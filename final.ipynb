{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-11T00:59:23.408751700Z",
     "start_time": "2024-09-11T00:59:21.149655900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " traincsv columns : Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
      "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n",
      "       '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36',\n",
      "       '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48',\n",
      "       '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60',\n",
      "       '61', '62', '63', '64', '65', 'TARGET'],\n",
      "      dtype='object')\n",
      " testcsv columns : Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
      "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n",
      "       '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36',\n",
      "       '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48',\n",
      "       '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60',\n",
      "       '61', '62', '63', '64', '65', 'TARGET'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "import xgboost as xg\n",
    "import numpy as np\n",
    "\n",
    "traincsv = pd.read_csv('D1_Project_train.csv')\n",
    "testcsv = pd.read_csv('D1_Project_test.csv')\n",
    "\n",
    "traincsv = traincsv.loc[:, traincsv.columns != \"Unnamed: 0\"]                # drop row numbers\n",
    "testcsv = testcsv.loc[:, testcsv.columns != \"Unnamed: 0\"]                      # drop row numbers\n",
    "\n",
    "traincsv['TARGET'].hist(bins = 100)\n",
    "print(f' traincsv columns : {traincsv.columns}')\n",
    "print(f' testcsv columns : {testcsv.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                   0             1             2             3             4  \\\ncount   90000.000000  90000.000000  90000.000000  90000.000000  90000.000000   \nmean    13365.474816   1071.217275  41413.144569  41413.140081     70.441719   \nstd      4877.338110      6.590974    119.751346    119.750603      0.026711   \nmin      1360.676509   1055.893735  41133.554350  41135.249380     70.376360   \n25%      9863.794843   1065.855739  41314.544980  41315.368445     70.421158   \n50%     12623.982775   1072.278611  41431.236300  41432.297400     70.441679   \n75%     15934.225878   1076.997455  41519.350160  41518.194795     70.462306   \nmax    118430.888400   1083.289247  41631.278570  41632.688790     70.507341   \n\n                  5             6             7             8             9  \\\ncount  90000.000000  90000.000000  90000.000000  90000.000000  90000.000000   \nmean       7.389048     70.376194  23229.769090  23229.768350     70.376238   \nstd        0.037951      0.015646      0.681655      0.486083      0.163505   \nmin        6.820728     69.904333  23212.605500  23214.665950     68.359808   \n25%        7.369758     70.372991  23229.537335  23229.630510     70.288810   \n50%        7.389044     70.376254  23229.770985  23229.770720     70.376262   \n75%        7.408451     70.379509  23230.003937  23229.910870     70.463364   \nmax        7.856652     71.059006  23252.083430  23249.481000     72.164583   \n\n       ...             57             58            59            60  \\\ncount  ...   90000.000000   90000.000000  90000.000000  90000.000000   \nmean   ...   23240.851029   23229.611010     70.275744      7.361860   \nstd    ...    8279.284791   22592.451585     98.832869     96.279683   \nmin    ... -219561.029900 -220411.452400  -2584.384588  -1730.472763   \n25%    ...   21860.573760   11671.079185     48.664525    -29.485785   \n50%    ...   23229.771070   23228.218475     70.371319      7.448268   \n75%    ...   24635.507025   34792.260763     92.289834     44.300721   \nmax    ...  163586.659600  252427.446300   4459.505439   1623.195216   \n\n                 61             62             63            64            65  \\\ncount  90000.000000   90000.000000   90000.000000  90000.000000  90000.000000   \nmean      70.188727   23264.552056   23219.576197     71.549145      7.525900   \nstd      193.250530   55733.137929    5429.353037    807.900381    177.209302   \nmin    -4591.956144 -784846.949600 -179886.020000 -18469.018900  -5282.912546   \n25%        7.534898   -3231.274488   22535.747703   -179.316365    -34.347827   \n50%       70.353191   23185.725210   23229.687545     70.828300      7.358205   \n75%      134.156904   49820.993022   23924.867363    325.392806     49.962365   \nmax     4698.530506  782554.338600  135436.826300  17814.491820   2823.471082   \n\n             TARGET  \ncount  90000.000000  \nmean      -0.000018  \nstd        0.007456  \nmin       -0.154823  \n25%       -0.001740  \n50%        0.000002  \n75%        0.001746  \nmax        0.218376  \n\n[8 rows x 67 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n      <th>60</th>\n      <th>61</th>\n      <th>62</th>\n      <th>63</th>\n      <th>64</th>\n      <th>65</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>...</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n      <td>90000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>13365.474816</td>\n      <td>1071.217275</td>\n      <td>41413.144569</td>\n      <td>41413.140081</td>\n      <td>70.441719</td>\n      <td>7.389048</td>\n      <td>70.376194</td>\n      <td>23229.769090</td>\n      <td>23229.768350</td>\n      <td>70.376238</td>\n      <td>...</td>\n      <td>23240.851029</td>\n      <td>23229.611010</td>\n      <td>70.275744</td>\n      <td>7.361860</td>\n      <td>70.188727</td>\n      <td>23264.552056</td>\n      <td>23219.576197</td>\n      <td>71.549145</td>\n      <td>7.525900</td>\n      <td>-0.000018</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4877.338110</td>\n      <td>6.590974</td>\n      <td>119.751346</td>\n      <td>119.750603</td>\n      <td>0.026711</td>\n      <td>0.037951</td>\n      <td>0.015646</td>\n      <td>0.681655</td>\n      <td>0.486083</td>\n      <td>0.163505</td>\n      <td>...</td>\n      <td>8279.284791</td>\n      <td>22592.451585</td>\n      <td>98.832869</td>\n      <td>96.279683</td>\n      <td>193.250530</td>\n      <td>55733.137929</td>\n      <td>5429.353037</td>\n      <td>807.900381</td>\n      <td>177.209302</td>\n      <td>0.007456</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1360.676509</td>\n      <td>1055.893735</td>\n      <td>41133.554350</td>\n      <td>41135.249380</td>\n      <td>70.376360</td>\n      <td>6.820728</td>\n      <td>69.904333</td>\n      <td>23212.605500</td>\n      <td>23214.665950</td>\n      <td>68.359808</td>\n      <td>...</td>\n      <td>-219561.029900</td>\n      <td>-220411.452400</td>\n      <td>-2584.384588</td>\n      <td>-1730.472763</td>\n      <td>-4591.956144</td>\n      <td>-784846.949600</td>\n      <td>-179886.020000</td>\n      <td>-18469.018900</td>\n      <td>-5282.912546</td>\n      <td>-0.154823</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>9863.794843</td>\n      <td>1065.855739</td>\n      <td>41314.544980</td>\n      <td>41315.368445</td>\n      <td>70.421158</td>\n      <td>7.369758</td>\n      <td>70.372991</td>\n      <td>23229.537335</td>\n      <td>23229.630510</td>\n      <td>70.288810</td>\n      <td>...</td>\n      <td>21860.573760</td>\n      <td>11671.079185</td>\n      <td>48.664525</td>\n      <td>-29.485785</td>\n      <td>7.534898</td>\n      <td>-3231.274488</td>\n      <td>22535.747703</td>\n      <td>-179.316365</td>\n      <td>-34.347827</td>\n      <td>-0.001740</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>12623.982775</td>\n      <td>1072.278611</td>\n      <td>41431.236300</td>\n      <td>41432.297400</td>\n      <td>70.441679</td>\n      <td>7.389044</td>\n      <td>70.376254</td>\n      <td>23229.770985</td>\n      <td>23229.770720</td>\n      <td>70.376262</td>\n      <td>...</td>\n      <td>23229.771070</td>\n      <td>23228.218475</td>\n      <td>70.371319</td>\n      <td>7.448268</td>\n      <td>70.353191</td>\n      <td>23185.725210</td>\n      <td>23229.687545</td>\n      <td>70.828300</td>\n      <td>7.358205</td>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>15934.225878</td>\n      <td>1076.997455</td>\n      <td>41519.350160</td>\n      <td>41518.194795</td>\n      <td>70.462306</td>\n      <td>7.408451</td>\n      <td>70.379509</td>\n      <td>23230.003937</td>\n      <td>23229.910870</td>\n      <td>70.463364</td>\n      <td>...</td>\n      <td>24635.507025</td>\n      <td>34792.260763</td>\n      <td>92.289834</td>\n      <td>44.300721</td>\n      <td>134.156904</td>\n      <td>49820.993022</td>\n      <td>23924.867363</td>\n      <td>325.392806</td>\n      <td>49.962365</td>\n      <td>0.001746</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>118430.888400</td>\n      <td>1083.289247</td>\n      <td>41631.278570</td>\n      <td>41632.688790</td>\n      <td>70.507341</td>\n      <td>7.856652</td>\n      <td>71.059006</td>\n      <td>23252.083430</td>\n      <td>23249.481000</td>\n      <td>72.164583</td>\n      <td>...</td>\n      <td>163586.659600</td>\n      <td>252427.446300</td>\n      <td>4459.505439</td>\n      <td>1623.195216</td>\n      <td>4698.530506</td>\n      <td>782554.338600</td>\n      <td>135436.826300</td>\n      <td>17814.491820</td>\n      <td>2823.471082</td>\n      <td>0.218376</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 67 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traincsv.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T00:59:23.594364Z",
     "start_time": "2024-09-11T00:59:23.407754Z"
    }
   },
   "id": "d3caaf9050c414c7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                  0             1             2             3             4  \\\ncount  19707.000000  19707.000000  19707.000000  19707.000000  19707.000000   \nmean    9975.260164   1078.291966  41541.678104  41541.671129     70.441791   \nstd     3934.982766      8.418171    152.946424    152.963293      0.030016   \nmin      325.859268   1061.267974  41231.194030  41232.291950     70.376293   \n25%     7531.492353   1070.574584  41402.658830  41402.067940     70.418640   \n50%     9896.037282   1080.274430  41576.505090  41576.958210     70.441713   \n75%    12387.922035   1084.993274  41664.618950  41663.784260     70.465179   \nmax    32945.873020   1094.824199  41843.228120  41842.105650     70.507341   \n\n                  5             6             7             8             9  \\\ncount  19707.000000  19707.000000  19707.000000  19707.000000  19707.000000   \nmean       7.389215     70.376332  23229.779446  23229.776988     70.376738   \nstd        0.046835      0.018461      0.833853      0.591788      0.206634   \nmin        7.018209     70.142222  23222.078010  23222.230240     68.434668   \n25%        7.364858     70.370975  23229.438815  23229.564575     70.265120   \n50%        7.389126     70.376260  23229.776020  23229.774360     70.377187   \n75%        7.413640     70.381662  23230.118620  23229.988295     70.489800   \nmax        7.956684     70.623575  23243.345480  23239.873680     72.377451   \n\n       ...             57             58            59            60  \\\ncount  ...   19707.000000   19707.000000  19707.000000  19707.000000   \nmean   ...   23213.873104   23240.484030     70.435130      7.548894   \nstd    ...    7651.541509   22829.217732     96.425010     95.342708   \nmin    ... -142767.442000 -135556.195400  -2294.735733  -1482.965085   \n25%    ...   21382.114850   11935.704155     48.460248    -28.581785   \n50%    ...   23229.776620   23142.410300     70.377186      7.417694   \n75%    ...   25146.733530   34473.526190     92.707505     44.366809   \nmax    ...  100780.537300  186167.793100   1907.060081   1634.587288   \n\n                 61             62            63            64            65  \\\ncount  19707.000000   19707.000000  19707.000000  19707.000000  19707.000000   \nmean      70.791803   23269.179827  23201.450509     71.010758      7.240163   \nstd      190.685448   56250.266596   5067.001142    752.099588    163.969095   \nmin    -3442.837570 -376857.699700 -99404.283480 -11171.096020  -3060.990061   \n25%        7.072419   -2241.406844  22381.098475   -190.860051    -39.790155   \n50%       70.219467   23241.617780  23229.771070     69.875124      7.447960   \n75%      134.018491   48918.672105  24070.920270    337.651272     55.045802   \nmax     3788.040760  461274.515500  89122.113170   6980.127157   1626.048157   \n\n             TARGET  \ncount  19707.000000  \nmean      -0.000066  \nstd        0.009020  \nmin       -0.171370  \n25%       -0.003099  \n50%        0.000003  \n75%        0.003053  \nmax        0.138727  \n\n[8 rows x 67 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n      <th>60</th>\n      <th>61</th>\n      <th>62</th>\n      <th>63</th>\n      <th>64</th>\n      <th>65</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>...</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n      <td>19707.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>9975.260164</td>\n      <td>1078.291966</td>\n      <td>41541.678104</td>\n      <td>41541.671129</td>\n      <td>70.441791</td>\n      <td>7.389215</td>\n      <td>70.376332</td>\n      <td>23229.779446</td>\n      <td>23229.776988</td>\n      <td>70.376738</td>\n      <td>...</td>\n      <td>23213.873104</td>\n      <td>23240.484030</td>\n      <td>70.435130</td>\n      <td>7.548894</td>\n      <td>70.791803</td>\n      <td>23269.179827</td>\n      <td>23201.450509</td>\n      <td>71.010758</td>\n      <td>7.240163</td>\n      <td>-0.000066</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3934.982766</td>\n      <td>8.418171</td>\n      <td>152.946424</td>\n      <td>152.963293</td>\n      <td>0.030016</td>\n      <td>0.046835</td>\n      <td>0.018461</td>\n      <td>0.833853</td>\n      <td>0.591788</td>\n      <td>0.206634</td>\n      <td>...</td>\n      <td>7651.541509</td>\n      <td>22829.217732</td>\n      <td>96.425010</td>\n      <td>95.342708</td>\n      <td>190.685448</td>\n      <td>56250.266596</td>\n      <td>5067.001142</td>\n      <td>752.099588</td>\n      <td>163.969095</td>\n      <td>0.009020</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>325.859268</td>\n      <td>1061.267974</td>\n      <td>41231.194030</td>\n      <td>41232.291950</td>\n      <td>70.376293</td>\n      <td>7.018209</td>\n      <td>70.142222</td>\n      <td>23222.078010</td>\n      <td>23222.230240</td>\n      <td>68.434668</td>\n      <td>...</td>\n      <td>-142767.442000</td>\n      <td>-135556.195400</td>\n      <td>-2294.735733</td>\n      <td>-1482.965085</td>\n      <td>-3442.837570</td>\n      <td>-376857.699700</td>\n      <td>-99404.283480</td>\n      <td>-11171.096020</td>\n      <td>-3060.990061</td>\n      <td>-0.171370</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>7531.492353</td>\n      <td>1070.574584</td>\n      <td>41402.658830</td>\n      <td>41402.067940</td>\n      <td>70.418640</td>\n      <td>7.364858</td>\n      <td>70.370975</td>\n      <td>23229.438815</td>\n      <td>23229.564575</td>\n      <td>70.265120</td>\n      <td>...</td>\n      <td>21382.114850</td>\n      <td>11935.704155</td>\n      <td>48.460248</td>\n      <td>-28.581785</td>\n      <td>7.072419</td>\n      <td>-2241.406844</td>\n      <td>22381.098475</td>\n      <td>-190.860051</td>\n      <td>-39.790155</td>\n      <td>-0.003099</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>9896.037282</td>\n      <td>1080.274430</td>\n      <td>41576.505090</td>\n      <td>41576.958210</td>\n      <td>70.441713</td>\n      <td>7.389126</td>\n      <td>70.376260</td>\n      <td>23229.776020</td>\n      <td>23229.774360</td>\n      <td>70.377187</td>\n      <td>...</td>\n      <td>23229.776620</td>\n      <td>23142.410300</td>\n      <td>70.377186</td>\n      <td>7.417694</td>\n      <td>70.219467</td>\n      <td>23241.617780</td>\n      <td>23229.771070</td>\n      <td>69.875124</td>\n      <td>7.447960</td>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>12387.922035</td>\n      <td>1084.993274</td>\n      <td>41664.618950</td>\n      <td>41663.784260</td>\n      <td>70.465179</td>\n      <td>7.413640</td>\n      <td>70.381662</td>\n      <td>23230.118620</td>\n      <td>23229.988295</td>\n      <td>70.489800</td>\n      <td>...</td>\n      <td>25146.733530</td>\n      <td>34473.526190</td>\n      <td>92.707505</td>\n      <td>44.366809</td>\n      <td>134.018491</td>\n      <td>48918.672105</td>\n      <td>24070.920270</td>\n      <td>337.651272</td>\n      <td>55.045802</td>\n      <td>0.003053</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>32945.873020</td>\n      <td>1094.824199</td>\n      <td>41843.228120</td>\n      <td>41842.105650</td>\n      <td>70.507341</td>\n      <td>7.956684</td>\n      <td>70.623575</td>\n      <td>23243.345480</td>\n      <td>23239.873680</td>\n      <td>72.377451</td>\n      <td>...</td>\n      <td>100780.537300</td>\n      <td>186167.793100</td>\n      <td>1907.060081</td>\n      <td>1634.587288</td>\n      <td>3788.040760</td>\n      <td>461274.515500</td>\n      <td>89122.113170</td>\n      <td>6980.127157</td>\n      <td>1626.048157</td>\n      <td>0.138727</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 67 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testcsv.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T00:59:23.719369500Z",
     "start_time": "2024-09-11T00:59:23.593366400Z"
    }
   },
   "id": "3ce10ad21852b5d0"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " max target value : 0.218375702, min target value : -0.154822771\n",
      "-0.02003159834\n",
      "0.019718635939999982\n"
     ]
    }
   ],
   "source": [
    "print(f' max target value : {max(traincsv[\"TARGET\"])}, min target value : {min(traincsv[\"TARGET\"])}')\n",
    "#  max target value : 0.218375702, min target value : -0.154822771\n",
    "\n",
    "print(traincsv['TARGET'].quantile(q=0.01))\n",
    "print(traincsv['TARGET'].quantile(q=0.99))\n",
    "\n",
    "# -0.02003159834\n",
    "# 0.019718635939999982"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T00:59:23.720366800Z",
     "start_time": "2024-09-11T00:59:23.684931800Z"
    }
   },
   "id": "3f7b9ffd37231114"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### CLIPPING\n",
    "lower, upper = 0.01, 0.99\n",
    "\n",
    "traincsv.clip(traincsv.quantile(lower), traincsv.quantile(upper), axis = 1)\n",
    "testcsv.clip(testcsv.quantile(lower), testcsv.quantile(upper), axis = 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6012127718abf5"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "### NORMALIZATION\n",
    "\n",
    "const = 0.001\n",
    "\n",
    "traincsv_feat = traincsv.loc[:, traincsv.columns != \"TARGET\"]\n",
    "traincsv_target = traincsv[\"TARGET\"]\n",
    "traincsv_ewm = traincsv_feat.ewm(alpha = const)\n",
    "temp = traincsv_feat.copy()\n",
    "traincsv_feat_norm = (temp - traincsv_ewm.mean())/traincsv_ewm.std()\n",
    "traincsv_feat_norm.fillna(0, inplace=True)\n",
    "traincsv_feat_norm = traincsv_feat_norm.loc[:, traincsv_feat_norm.columns != \"mean\"]\n",
    "traincsv_feat_norm = traincsv_feat_norm[1:]\n",
    "traincsv_target = traincsv_target[1:]\n",
    "\n",
    "testcsv_feat = testcsv.loc[:, testcsv.columns != \"TARGET\"]\n",
    "testcsv_target = testcsv[\"TARGET\"]\n",
    "testcsv_ewm = testcsv_feat.ewm(alpha = const)\n",
    "temp = testcsv_feat.copy()\n",
    "testcsv_feat_norm = (temp - testcsv_ewm.mean())/testcsv_ewm.std()\n",
    "testcsv_feat_norm.fillna(0, inplace=True)\n",
    "testcsv_feat_norm = testcsv_feat_norm.loc[:, testcsv_feat_norm.columns != \"mean\"]\n",
    "testcsv_feat_norm = testcsv_feat_norm[1:]\n",
    "testcsv_target = testcsv_target[1:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T02:15:45.414383200Z",
     "start_time": "2024-09-11T02:15:44.977960500Z"
    }
   },
   "id": "4ffbfa67a81fce98"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS score : 0.00255602\n",
      "alpha :  0.0010 / Ridge score :  0.00255605\n",
      "alpha :  0.0010 / Lasso score : -0.00002899\n",
      "alpha :  0.0050 / Ridge score :  0.00255615\n",
      "alpha :  0.0050 / Lasso score : -0.00002899\n",
      "alpha :  0.0100 / Ridge score :  0.00255627\n",
      "alpha :  0.0100 / Lasso score : -0.00002899\n",
      "alpha :  0.0500 / Ridge score :  0.00255725\n",
      "alpha :  0.0500 / Lasso score : -0.00002899\n",
      "alpha :  0.1000 / Ridge score :  0.00255843\n",
      "alpha :  0.1000 / Lasso score : -0.00002899\n",
      "alpha :  1.0000 / Ridge score :  0.00257580\n",
      "alpha :  1.0000 / Lasso score : -0.00002899\n",
      "alpha :  10.0000 / Ridge score :  0.00266484\n",
      "alpha :  10.0000 / Lasso score : -0.00002899\n",
      "alpha :  50.0000 / Ridge score :  0.00277931\n",
      "alpha :  50.0000 / Lasso score : -0.00002899\n",
      "alpha :  100.0000 / Ridge score :  0.00281110\n",
      "alpha :  100.0000 / Lasso score : -0.00002899\n"
     ]
    }
   ],
   "source": [
    "### MODEL SELECTION\n",
    "\n",
    "OLS = sklearn.linear_model.LinearRegression().fit(traincsv_feat_norm, traincsv_target)\n",
    "OLS_score = sklearn.metrics.r2_score(testcsv_target, OLS.predict(testcsv_feat_norm))\n",
    "print(f\"OLS score : {OLS_score:.8f}\")\n",
    "\n",
    "alphas = [0.001, 0.005, 0.01, 0.05, 0.1, 1, 10, 50, 100]\n",
    "\n",
    "for alpha in alphas:\n",
    "    Ridge = sklearn.linear_model.Ridge(alpha = alpha).fit(traincsv_feat_norm, traincsv_target)\n",
    "    Lasso = sklearn.linear_model.Lasso(alpha = alpha).fit(traincsv_feat_norm, traincsv_target)\n",
    "    print(f\"alpha : {alpha: 3.4f} / Ridge score : {sklearn.metrics.r2_score(testcsv_target, Ridge.predict(testcsv_feat_norm)): .8f}\")\n",
    "    print(f\"alpha : {alpha: 3.4f} / Lasso score : {sklearn.metrics.r2_score(testcsv_target, Lasso.predict(testcsv_feat_norm)): .8f}\")\n",
    "    \n",
    "    \n",
    "# OLS score : 0.00255602\n",
    "# alpha :  0.0010 / Ridge score :  0.00255605\n",
    "# alpha :  0.0010 / Lasso score : -0.00002899\n",
    "# alpha :  0.0050 / Ridge score :  0.00255615\n",
    "# alpha :  0.0050 / Lasso score : -0.00002899\n",
    "# alpha :  0.0100 / Ridge score :  0.00255627\n",
    "# alpha :  0.0100 / Lasso score : -0.00002899\n",
    "# alpha :  0.0500 / Ridge score :  0.00255725\n",
    "# alpha :  0.0500 / Lasso score : -0.00002899\n",
    "# alpha :  0.1000 / Ridge score :  0.00255843\n",
    "# alpha :  0.1000 / Lasso score : -0.00002899\n",
    "# alpha :  1.0000 / Ridge score :  0.00257580\n",
    "# alpha :  1.0000 / Lasso score : -0.00002899\n",
    "# alpha :  10.0000 / Ridge score :  0.00266484\n",
    "# alpha :  10.0000 / Lasso score : -0.00002899\n",
    "# alpha :  50.0000 / Ridge score :  0.00277931\n",
    "# alpha :  50.0000 / Lasso score : -0.00002899\n",
    "# alpha :  100.0000 / Ridge score :  0.00281110\n",
    "# alpha :  100.0000 / Lasso score : -0.00002899"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T02:15:47.325180400Z",
     "start_time": "2024-09-11T02:15:45.980903800Z"
    }
   },
   "id": "90a72b1529beda3b"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.95181379600008\n"
     ]
    }
   ],
   "source": [
    "### IDEAL PROFIT: 100% correct model\n",
    "\n",
    "ideal_return = 0\n",
    "for number in testcsv_target:\n",
    "    ideal_return += number * (number > 0)\n",
    "print(ideal_return)\n",
    "\n",
    "# 55.95181379600008"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T01:36:45.673314300Z",
     "start_time": "2024-09-11T01:36:45.659693300Z"
    }
   },
   "id": "4e96a6dc16b4387f"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my final return is  3.7141212272 out of  55.9518137960\n",
      "up/down prediction score : 48.63493352278494% win rate\n"
     ]
    }
   ],
   "source": [
    "### actual trading model\n",
    "\n",
    "my_return = 0\n",
    "final_model = sklearn.linear_model.Ridge(alpha = 100).fit(traincsv_feat_norm, traincsv_target)\n",
    "testcsv_predict = final_model.predict(testcsv_feat_norm)\n",
    "\n",
    "count = len(testcsv_target)\n",
    "correct = 0\n",
    "for i in range(count):\n",
    "    my_return += testcsv_target.iloc[i] * (testcsv_predict[i] > 0)\n",
    "    correct += (testcsv_target.iloc[i] * testcsv_predict[i] > 0)\n",
    "print(f'my final return is {my_return: .10f} out of {ideal_return: .10f}')\n",
    "print(f'up/down prediction score : {correct / count * 100}% win rate')\n",
    "\n",
    "\n",
    "# my final return is  3.7141212272 out of  55.9518137960\n",
    "# up/down prediction score : 48.63493352278494% win rate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T01:52:09.667601600Z",
     "start_time": "2024-09-11T01:52:09.395422400Z"
    }
   },
   "id": "d304720cd4c81458"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### THOUGHTS\n",
    "\n",
    "* Can clipping be done in a better way, rather than considering a quantile? we can also abort those outlier rows.\n",
    "* There might be a better constant than 0.001 for the moving window average constant.\n",
    "* Ridge regression gives the best performance when the penalizing constant is larger than 100. There must be a way to\n",
    " handle this problem.\n",
    "* Does normalizing the \"TARGET\" give a better result? Doubt about it.\n",
    "* What about XGboost model?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96530ed25b2a25ff"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator :  50.000000 / regression via xgboost r2 score : -1.227095\n",
      "my final return is  8.5472560364 out of  55.9518137960\n",
      "up/down prediction score : 49.32257573451058% win rate\n",
      "estimator :  100.000000 / regression via xgboost r2 score : -1.620240\n",
      "my final return is  11.7856402696 out of  55.9518137960\n",
      "up/down prediction score : 49.70822550362815% win rate\n",
      "estimator :  500.000000 / regression via xgboost r2 score : -1.886139\n",
      "my final return is  14.9610428778 out of  55.9518137960\n",
      "up/down prediction score : 49.93149642259096% win rate\n",
      "estimator :  1000.000000 / regression via xgboost r2 score : -1.942191\n",
      "my final return is  17.6335478630 out of  55.9518137960\n",
      "up/down prediction score : 49.89090171005227% win rate\n",
      "estimator :  5000.000000 / regression via xgboost r2 score : -1.812021\n",
      "my final return is  19.9309850482 out of  55.9518137960\n",
      "up/down prediction score : 50.59623484041204% win rate\n"
     ]
    }
   ],
   "source": [
    "### XGboost try\n",
    "\n",
    "traincsv_feat = traincsv.drop(columns = [\"TARGET\", \"mean\"])\n",
    "traincsv_target = traincsv[\"TARGET\"]\n",
    "testcsv_feat = testcsv.drop(columns = [\"TARGET\"])\n",
    "testcsv_target = testcsv[\"TARGET\"]\n",
    "# XGboost does not require normalization process\n",
    "\n",
    "count = len(testcsv_target)\n",
    "\n",
    "estimators = [50, 100, 500, 1000, 5000]\n",
    "for estimator in estimators:\n",
    "    xgLR = xg.XGBRegressor(n_estimators = estimator, max_depth = 3).fit(traincsv_feat, traincsv_target)\n",
    "    r2_xgLR = sklearn.metrics.r2_score(testcsv_target, xgLR.predict(testcsv_feat))\n",
    "    print(f'estimator : {estimator: 5f} / regression via xgboost r2 score : {r2_xgLR: .6f}')\n",
    "    testcsv_predict = xgLR.predict(testcsv_feat)\n",
    "    correct = 0\n",
    "    for i in range(count):\n",
    "        my_return += testcsv_target.iloc[i] * (testcsv_predict[i] > 0)\n",
    "        correct += (testcsv_target.iloc[i] * testcsv_predict[i] > 0)\n",
    "    print(f'my final return is {my_return: .10f} out of {ideal_return: .10f}')\n",
    "    print(f'up/down prediction score : {correct / count * 100}% win rate')\n",
    "\n",
    "\n",
    "# estimator :  50.000000 / regression via xgboost r2 score : -1.227095\n",
    "# my final return is  8.5472560364 out of  55.9518137960\n",
    "# up/down prediction score : 49.32257573451058% win rate\n",
    "# estimator :  100.000000 / regression via xgboost r2 score : -1.620240\n",
    "# my final return is  11.7856402696 out of  55.9518137960\n",
    "# up/down prediction score : 49.70822550362815% win rate\n",
    "# estimator :  500.000000 / regression via xgboost r2 score : -1.886139\n",
    "# my final return is  14.9610428778 out of  55.9518137960\n",
    "# up/down prediction score : 49.93149642259096% win rate\n",
    "# estimator :  1000.000000 / regression via xgboost r2 score : -1.942191\n",
    "# my final return is  17.6335478630 out of  55.9518137960\n",
    "# up/down prediction score : 49.89090171005227% win rate\n",
    "# estimator :  5000.000000 / regression via xgboost r2 score : -1.812021\n",
    "# my final return is  19.9309850482 out of  55.9518137960\n",
    "# up/down prediction score : 50.59623484041204% win rate\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T02:12:44.051868900Z",
     "start_time": "2024-09-11T02:07:55.836396200Z"
    }
   },
   "id": "fd319806cb410953"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "\n",
    "XGboost does not give the best r2 score, nonetheless, in terms of actual return XGboost was the best. We may try more\n",
    " leaves to figure out the best return but calculation power was not enough at my local pc.\n",
    "\n",
    "Final model : XGboost with 5000 estimators, 3 layers, only with clippings.\n",
    "\n",
    "\n",
    "# my final return is  19.9309850482 out of  55.9518137960\n",
    "# up/down prediction score : 50.59623484041204% win rate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd1e5451eb43869e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f6e708dacd40198b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
